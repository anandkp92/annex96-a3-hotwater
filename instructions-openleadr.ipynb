{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenADR 3 Demand Flexibility for Hot Water Heaters (openleadr-rs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This project demonstrates how to use **OpenADR 3.0** to communicate demand flexibility signals for heat pump water heaters (HPWHs). The system fetches electricity pricing data, publishes it through an OpenADR 3 Virtual Top Node (VTN), and converts price signals into CTA-2045 control schedules for water heaters.\n",
    "\n",
    "This version uses **[openleadr-rs](https://github.com/OpenLEADR/openleadr-rs)** — a production-ready Rust implementation of OpenADR 3.0 that provides both the VTN server and a VEN client library. It passes 166/168 OpenADR Alliance test cases.\n",
    "\n",
    "### What is OpenADR 3?\n",
    "\n",
    "OpenADR (Open Automated Demand Response) is an open standard for communicating demand response signals between utilities/aggregators and end devices. Version 3.0 uses a REST API architecture with the following key concepts:\n",
    "\n",
    "- **VTN (Virtual Top Node)** — the server that publishes programs, events, and price signals\n",
    "- **VEN (Virtual End Node)** — the client that receives signals and controls devices\n",
    "- **Programs** — define demand response programs with their parameters\n",
    "- **Events** — time-based signals (e.g., price schedules) published under a program\n",
    "- **Reports** — telemetry data sent from VENs back to the VTN\n",
    "- **Subscriptions** — webhook registrations for change notifications (not yet implemented in openleadr-rs)\n",
    "\n",
    "### Architecture\n",
    "\n",
    "```\n",
    "Pricing API                  openleadr-rs VTN           VEN / Control Algorithm\n",
    "(Olivine)                    (Rust, PostgreSQL)         (Thermal Systems)\n",
    "┌──────────────┐             ┌──────────────┐           ┌──────────────────┐\n",
    "│  Electricity │  fetch      │              │  OpenADR  │  Price → CTA2045 │\n",
    "│  Price Data  │ ─────────> │  Programs &  │ ────────> │  Schedule for    │\n",
    "│  (eTOU-Dyn)  │  & publish │  Events      │  signals  │  Water Heater    │\n",
    "└──────────────┘             └──────────────┘           └──────────────────┘\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Prerequisites\n\n| Requirement | macOS | Linux (Ubuntu/Debian) |\n|---|---|---|\n| **Rust 1.90+** | `curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs \\| sh` | Same — then `source $HOME/.cargo/env` |\n| **cargo-sqlx** | `cargo install sqlx-cli` | Same |\n| **Docker & Docker Compose** | [Docker Desktop for Mac](https://docs.docker.com/desktop/install/mac-install/) | `sudo apt install docker.io docker-compose-v2` (or [Docker Desktop](https://docs.docker.com/desktop/install/linux/)) |\n| **Python 3.9+** | `brew install python@3.12` (or any 3.9+) | `sudo apt install python3 python3-venv` |\n| **pip** | Included with Python from Homebrew | `sudo apt install python3-pip` |\n| **Git** | `brew install git` (or Xcode CLT: `xcode-select --install`) | `sudo apt install git` |\n| **curl** | Pre-installed on macOS | `sudo apt install curl` |\n\n> **Note:** A local `psql` client is **not** required. Test credentials are loaded via `docker compose exec` using the `psql` already inside the PostgreSQL container.\n\n### Quick install\n\n**macOS (Homebrew):**\n```bash\nbrew install python@3.12 git\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\ncargo install sqlx-cli\npip install requests isodate matplotlib numpy jupyter\n```\n\n**Linux (Ubuntu/Debian):**\n```bash\nsudo apt update\nsudo apt install -y python3 python3-pip python3-venv git curl docker.io docker-compose-v2\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\ncargo install sqlx-cli\npip install requests isodate matplotlib numpy jupyter\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Component 1: openleadr-rs VTN (Virtual Top Node)\n\n### What is it?\n\nThe openleadr-rs VTN is a Rust-based OpenADR 3.0 server built with Axum (async web framework) and backed by PostgreSQL. It provides full CRUD operations for all OpenADR 3 resources and includes built-in OAuth authentication with role-based access control.\n\n### Setup\n\n> **Note:** `cargo-sqlx` must be installed first: `cargo install sqlx-cli`\n\n#### Option A: Docker Compose (Recommended)\n\nThis starts both the VTN server and PostgreSQL database:\n\n```bash\ncd openleadr-rs\n\n# Install sqlx CLI (one-time, if not already installed)\ncargo install sqlx-cli\n\n# Start PostgreSQL first\ndocker compose up -d db\n\n# Run database migrations\ncargo sqlx migrate run\n\n# Load test user credentials (uses psql inside the container — no local psql needed)\ndocker compose exec -T db psql -U openadr openadr < fixtures/test_user_credentials.sql\n\n# Start VTN and DB together\ndocker compose up -d\n```\n\n#### Option B: Run VTN Locally (with Docker for PostgreSQL only)\n\n```bash\ncd openleadr-rs\n\n# Install sqlx CLI (one-time, if not already installed)\ncargo install sqlx-cli\n\n# Start PostgreSQL via Docker\ndocker compose up -d db\n\n# Run database migrations\ncargo sqlx migrate run\n\n# Load test user credentials (uses psql inside the container — no local psql needed)\ndocker compose exec -T db psql -U openadr openadr < fixtures/test_user_credentials.sql\n\n# Run VTN locally with debug logging\nRUST_LOG=debug cargo run --bin openleadr-vtn\n```\n\n### Configuration\n\nConfiguration is via environment variables (also defined in `.env`):\n\n| Variable | Default | Description |\n|---|---|---|\n| `DATABASE_URL` | `postgres://openadr:openadr@localhost:5432/openadr` | PostgreSQL connection string |\n| `VTN_PORT` | `3000` | VTN HTTP server port |\n| `PG_PORT` | `5432` | PostgreSQL port |\n| `PG_USER` | `openadr` | PostgreSQL user |\n| `PG_PASSWORD` | `openadr` | PostgreSQL password |\n| `PG_DB` | `openadr` | PostgreSQL database name |\n| `RUST_LOG` | `info` | Log level (`trace`, `debug`, `info`, `warn`, `error`) |\n\n#### OAuth Configuration\n\nThe VTN supports both internal and external OAuth providers:\n\n**Internal OAuth (default):**\n\n| Variable | Description |\n|---|---|\n| `OAUTH_TYPE` | `INTERNAL` (default) |\n| `OAUTH_BASE64_SECRET` | Base64-encoded secret key (≥256 bits). Auto-generated if not set. |\n| `OAUTH_KEY_TYPE` | `HMAC` (only option for internal) |\n\n**External OAuth:**\n\n| Variable | Description |\n|---|---|\n| `OAUTH_TYPE` | `EXTERNAL` |\n| `OAUTH_KEY_TYPE` | `HMAC`, `RSA`, `EC`, or `ED` |\n| `OAUTH_PEM` | Path to PEM-encoded key (for RSA/EC/ED) |\n| `OAUTH_JWKS_LOCATION` | URL to JWKS endpoint (alternative to PEM) |\n| `OAUTH_VALID_AUDIENCES` | Comma-separated list of valid audiences (required) |\n\n### Default Test Users\n\nAfter loading `fixtures/test_user_credentials.sql`, the following users are available (password = client_id):\n\n| Client ID | Role | Description |\n|---|---|---|\n| `ven-manager` | VEN Manager | Can create/manage VENs |\n| `user-manager` | User Manager | Can create/manage users |\n| `any-business` | Any Business | Can manage programs, events, reports |\n| `business-1` | Business 1 | Scoped to business-1 |\n| `ven-1` | VEN 1 | Scoped to ven-1 |\n\n### Verify it's running\n\n```bash\n# Health check\ncurl http://localhost:3000/health\n\n# Get an OAuth token (using internal OAuth)\nTOKEN=$(curl -s -X POST http://localhost:3000/auth/token \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"grant_type=client_credentials&client_id=any-business&client_secret=any-business\" \\\n  | python3 -c \"import sys,json; print(json.load(sys.stdin)['access_token'])\")\n\n# List programs (should return empty list)\ncurl -H \"Authorization: Bearer $TOKEN\" http://localhost:3000/programs\n```\n\nExpected response: `[]`\n\n### API Endpoints\n\nThe VTN listens at `http://localhost:3000` and exposes:\n\n| Method | Endpoint | Description |\n|---|---|---|\n| GET | `/health` | Health check |\n| POST | `/auth/token` | Get OAuth token |\n| GET/POST | `/programs` | List / Create programs |\n| GET/PUT/DELETE | `/programs/{id}` | Get / Update / Delete program |\n| GET/POST | `/events` | List / Create events |\n| GET/PUT/DELETE | `/events/{id}` | Get / Update / Delete event |\n| GET/POST | `/reports` | List / Create reports |\n| GET/PUT/DELETE | `/reports/{id}` | Get / Update / Delete report |\n| GET/POST | `/vens` | List / Create VENs |\n| GET/PUT/DELETE | `/vens/{id}` | Get / Update / Delete VEN |\n| GET/POST | `/vens/{venId}/resources` | List / Create resources |\n| GET/PUT/DELETE | `/vens/{venId}/resources/{id}` | Get / Update / Delete resource |\n| GET/POST | `/users` | List / Create users (internal OAuth) |\n| GET/PUT/DELETE | `/users/{id}` | Get / Update / Delete user |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Component 2: openleadr-rs VEN Client Library\n",
    "\n",
    "### What is it?\n",
    "\n",
    "The openleadr-rs client library (`openleadr-client`) is a Rust crate for building VEN applications. It provides an ergonomic API for interacting with any OpenADR 3.0 VTN. The repo also includes example binaries demonstrating typical VEN patterns.\n",
    "\n",
    "### Using the Client Library (Rust)\n",
    "\n",
    "Add to your `Cargo.toml`:\n",
    "\n",
    "```toml\n",
    "[dependencies]\n",
    "openleadr-client = \"0.1.3\"\n",
    "tokio = { version = \"1\", features = [\"full\"] }\n",
    "```\n",
    "\n",
    "#### Example: Connect to VTN and read programs\n",
    "\n",
    "```rust\n",
    "use openleadr_client::{Client, ClientCredentials};\n",
    "\n",
    "#[tokio::main]\n",
    "async fn main() {\n",
    "    let credentials = ClientCredentials::new(\n",
    "        \"any-business\".to_string(),\n",
    "        \"any-business\".to_string(),\n",
    "    );\n",
    "    let client = Client::with_url(\n",
    "        \"http://localhost:3000\".try_into().unwrap(),\n",
    "        Some(credentials),\n",
    "    );\n",
    "\n",
    "    // Create a program\n",
    "    let new_program = ProgramContent::new(\"etou-dynamic-pricing\".to_string());\n",
    "    let program = client.create_program(new_program).await.unwrap();\n",
    "\n",
    "    // Create an event with price intervals\n",
    "    let mut new_event = program.new_event();\n",
    "    new_event.event_name = Some(\"hourly-prices\".to_string());\n",
    "    program.create_event(new_event).await.unwrap();\n",
    "}\n",
    "```\n",
    "\n",
    "### Example Binaries\n",
    "\n",
    "The repo includes two example binaries in `openleadr-client/src/bin/`:\n",
    "\n",
    "| Binary | Description |\n",
    "|---|---|\n",
    "| `cli` | Basic example: authenticates and creates programs |\n",
    "| `everest` | Advanced VEN simulator: polls timeline from VTN, listens for event updates |\n",
    "\n",
    "```bash\n",
    "# Build and run the CLI example\n",
    "cargo run --bin cli\n",
    "\n",
    "# Build and run the everest VEN simulator\n",
    "cargo run --bin everest\n",
    "```\n",
    "\n",
    "### Using the VTN via REST API (any language)\n",
    "\n",
    "The VTN is language-agnostic — any HTTP client can interact with it. Here are curl examples:\n",
    "\n",
    "```bash\n",
    "# Step 1: Get an OAuth token\n",
    "TOKEN=$(curl -s -X POST http://localhost:3000/auth/token \\\n",
    "  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n",
    "  -d \"grant_type=client_credentials&client_id=any-business&client_secret=any-business\" \\\n",
    "  | python3 -c \"import sys,json; print(json.load(sys.stdin)['access_token'])\")\n",
    "\n",
    "# Step 2: Create a program\n",
    "curl -X POST http://localhost:3000/programs \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer $TOKEN\" \\\n",
    "  -d '{\n",
    "    \"programName\": \"etou-dynamic-pricing\",\n",
    "    \"programLongName\": \"Dynamic Time-of-Use Pricing\",\n",
    "    \"programType\": \"PRICING\",\n",
    "    \"retailerName\": \"Demo Utility\",\n",
    "    \"country\": \"US\",\n",
    "    \"principalSubdivision\": \"CA\",\n",
    "    \"payloadDescriptors\": [\n",
    "      {\n",
    "        \"objectType\": \"EVENT_PAYLOAD_DESCRIPTOR\",\n",
    "        \"payloadType\": \"PRICE\",\n",
    "        \"units\": \"KWH\",\n",
    "        \"currency\": \"USD\"\n",
    "      }\n",
    "    ]\n",
    "  }'\n",
    "\n",
    "# Step 3: Create an event with hourly price intervals\n",
    "curl -X POST http://localhost:3000/events \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer $TOKEN\" \\\n",
    "  -d '{\n",
    "    \"programID\": \"<program-id-from-step-2>\",\n",
    "    \"eventName\": \"hourly-prices-day-1\",\n",
    "    \"payloadDescriptors\": [\n",
    "      {\n",
    "        \"objectType\": \"EVENT_PAYLOAD_DESCRIPTOR\",\n",
    "        \"payloadType\": \"PRICE\",\n",
    "        \"currency\": \"USD\",\n",
    "        \"units\": \"KWH\"\n",
    "      }\n",
    "    ],\n",
    "    \"intervalPeriod\": {\n",
    "      \"start\": \"2024-01-01T00:00:00Z\",\n",
    "      \"duration\": \"PT1H\"\n",
    "    },\n",
    "    \"intervals\": [\n",
    "      { \"id\": 0, \"payloads\": [{ \"type\": \"PRICE\", \"values\": [0.12] }] },\n",
    "      { \"id\": 1, \"payloads\": [{ \"type\": \"PRICE\", \"values\": [0.11] }] },\n",
    "      { \"id\": 2, \"payloads\": [{ \"type\": \"PRICE\", \"values\": [0.10] }] }\n",
    "    ]\n",
    "  }'\n",
    "\n",
    "# Step 4: Read events (as a VEN would)\n",
    "VEN_TOKEN=$(curl -s -X POST http://localhost:3000/auth/token \\\n",
    "  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n",
    "  -d \"grant_type=client_credentials&client_id=ven-1&client_secret=ven-1\" \\\n",
    "  | python3 -c \"import sys,json; print(json.load(sys.stdin)['access_token'])\")\n",
    "\n",
    "curl -H \"Authorization: Bearer $VEN_TOKEN\" http://localhost:3000/events\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Component 3: Thermal Systems / Control Algorithms\n",
    "\n",
    "### What is it?\n",
    "\n",
    "The `thermal_systems` library (developed by LBNL) contains simulation models and control strategies for heat pump water heaters. The key module for this project is the **control algorithms** that convert electricity price signals into CTA-2045 set temperature schedules.\n",
    "\n",
    "### Key Files\n",
    "\n",
    "- **`controls/hpwh_fleet_control/control_algorithms.py`** — Price-responsive control algorithms including:\n",
    "  - `MinMax_Supervisory` — determines set temperatures based on price thresholds (mean +/- standard deviation)\n",
    "  - `StateOfCharge_Adjustment` — adjusts price thresholds based on tank state of charge\n",
    "\n",
    "### How the Control Algorithm Works\n",
    "\n",
    "1. Takes a price schedule (e.g., 24-hour ahead prices)\n",
    "2. Computes mean and standard deviation of prices\n",
    "3. **High price periods** (price > mean + stdev) → lower set temperature (48.9°C) to reduce consumption\n",
    "4. **Low price periods** (price < mean - adjusted stdev) → higher set temperature to pre-heat\n",
    "5. **Normal periods** → default set temperature (51.6°C)\n",
    "6. State of charge adjustment makes pre-heating more likely when the tank is low\n",
    "\n",
    "### Available Resources\n",
    "\n",
    "The `thermal_systems/resources/` folder contains supporting data:\n",
    "\n",
    "| Resource | Description |\n",
    "|---|---|\n",
    "| `electricity_prices/` | Price data for 25 climate zones |\n",
    "| `emissions/` | Marginal CO2 emissions data |\n",
    "| `weather/` | Weather datasets |\n",
    "| `hot_water_draws/` | Hot water usage profiles |\n",
    "| `hpwh_config_files/` | HPWH configuration files |\n",
    "| `hpwh_signal_schedules/` | Control signal schedules |\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "```bash\n",
    "pip install pandas numpy matplotlib jupyter\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Component 4: Pricing Data Source\n",
    "\n",
    "### API Endpoint\n",
    "\n",
    "Electricity pricing data is sourced from the Olivine API:\n",
    "\n",
    "```\n",
    "https://api.olivineinc.com/i/oe/pricing/signal/paced/etou-dyn\n",
    "```\n",
    "\n",
    "This provides dynamic time-of-use (eTOU-Dyn) pricing signals.\n",
    "\n",
    "### Fetching and Publishing Prices\n",
    "\n",
    "The workflow is:\n",
    "1. **Fetch** prices from the Olivine API\n",
    "2. **Authenticate** with the VTN (`POST /auth/token` with business credentials)\n",
    "3. **Create a program** on the VTN to represent the pricing program\n",
    "4. **Create events** on the VTN with price intervals from the fetched data\n",
    "5. VENs poll the VTN to get updated pricing events"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## OpenADR 3.0.0 Specification Reference\n",
    "\n",
    "The OpenADR 3 specification is included in `specification/`. This project uses **version 3.0.0**.\n",
    "\n",
    "### Specification Files\n",
    "\n",
    "- `specification/3.0.0/oadr3.0.0.yaml` — OpenAPI 3.0 definition (the source of truth for the API)\n",
    "- `specification/3.0.0/release_notes.txt` — Changes from 3.0.0 to 3.0.1\n",
    "\n",
    "Other versions available for reference: `3.0.1/`, `3.1.0/`, `3.1.1/`\n",
    "\n",
    "### Dynamic Pricing Example (from openleadr-rs)\n",
    "\n",
    "The openleadr-rs repo includes example YAML files in `tests/` that show how OpenADR 3 events are structured:\n",
    "\n",
    "- `tests/dyn-price.oadr.yaml` — 24-hour dynamic pricing with hourly intervals\n",
    "- `tests/load-sched.oadr.yaml` — Load scheduling example\n",
    "- `tests/state-of-charge.oadr.yaml` — EV charging state-of-charge example\n",
    "\n",
    "### Key API Resources\n",
    "\n",
    "| Resource | Endpoint | Description |\n",
    "|---|---|---|\n",
    "| Programs | `/programs` | Define demand response programs |\n",
    "| Events | `/events` | Time-based signals (prices, load control) under a program |\n",
    "| Reports | `/reports` | Telemetry data from VENs |\n",
    "| Subscriptions | `/subscriptions` | Webhook registrations (not yet in openleadr-rs) |\n",
    "| VENs | `/vens` | Register and manage Virtual End Nodes |\n",
    "| Resources | `/vens/{venID}/resources` | Devices/assets managed by a VEN |\n",
    "| Auth | `/auth/token` | Obtain access tokens |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n## Quick Start: End-to-End Setup\n\nFor an interactive Python notebook version of Steps 2–6 below, see **`quickstart-openleadr.ipynb`**.\n\n### Step 1: Install prerequisites\n\n**macOS (Homebrew):**\n```bash\nbrew install python@3.12 git\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\ncargo install sqlx-cli\npip install requests isodate matplotlib numpy jupyter\n```\n\n**Linux (Ubuntu/Debian):**\n```bash\nsudo apt update\nsudo apt install -y python3 python3-pip python3-venv git curl docker.io docker-compose-v2\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\nsource $HOME/.cargo/env\ncargo install sqlx-cli\npip install requests isodate matplotlib numpy jupyter\n```\n\n### Step 2: Start PostgreSQL and VTN\n\n```bash\n# Terminal 1\ncd openleadr-rs\n\n# Start PostgreSQL\ndocker compose up -d db\n\n# Run database migrations\ncargo sqlx migrate run\n\n# Load test users (uses psql inside the container — no local psql needed)\ndocker compose exec -T db psql -U openadr openadr < fixtures/test_user_credentials.sql\n\n# Start the VTN\nRUST_LOG=debug cargo run --bin openleadr-vtn\n```\n\nVerify: `curl http://localhost:3000/health` should return a success response.\n\n### Step 3: Get an OAuth Token\n\n```bash\n# Terminal 2\nTOKEN=$(curl -s -X POST http://localhost:3000/auth/token \\\n  -H \"Content-Type: application/x-www-form-urlencoded\" \\\n  -d \"grant_type=client_credentials&client_id=any-business&client_secret=any-business\" \\\n  | python3 -c \"import sys,json; print(json.load(sys.stdin)['access_token'])\")\n\necho $TOKEN\n```\n\n### Step 4: Create a Program and Publish Prices\n\n```bash\n# Create a pricing program\nPROGRAM=$(curl -s -X POST http://localhost:3000/programs \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $TOKEN\" \\\n  -d '{\n    \"programName\": \"etou-dynamic-pricing\",\n    \"programLongName\": \"Dynamic Time-of-Use Pricing\",\n    \"programType\": \"PRICING\",\n    \"retailerName\": \"Demo Utility\",\n    \"country\": \"US\",\n    \"principalSubdivision\": \"CA\",\n    \"payloadDescriptors\": [\n      {\n        \"objectType\": \"EVENT_PAYLOAD_DESCRIPTOR\",\n        \"payloadType\": \"PRICE\",\n        \"units\": \"KWH\",\n        \"currency\": \"USD\"\n      }\n    ]\n  }')\n\necho $PROGRAM\nPROGRAM_ID=$(echo $PROGRAM | python3 -c \"import sys,json; print(json.load(sys.stdin)['id'])\")\n```\n\n### Step 5: Fetch Prices, Create Events, and Run Control Algorithm\n\nOpen `quickstart-openleadr.ipynb` in Jupyter and run all cells. The notebook will:\n\n1. Fetch live prices from the Olivine API\n2. Publish them as an OpenADR 3 event on the VTN\n3. Read the events back as a VEN\n4. Run the Easy Shift control algorithm to generate an optimal HPWH schedule\n\n```bash\ncd annex96-a3-hotwater\njupyter notebook quickstart-openleadr.ipynb\n```\n\n### Step 6: Run Integration Tests (Optional)\n\n```bash\ncd openleadr-rs\ncargo test --workspace\n```"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}